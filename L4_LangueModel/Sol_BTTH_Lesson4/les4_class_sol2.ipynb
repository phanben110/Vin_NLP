{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### Mô hình ngôn ngữ và ứng dụng trong việc sinh văn bản\n",
    "\n",
    "#### Mục tiêu: xây dựng chương trình sinh văn bản tiếng Việt đơn giản \n",
    "\n",
    "Bài 2: Dùng mô hình vừa xây dựng để sinh các từ tiếp theo với một chuỗi từ cho trước.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đọc input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['Nga không kích nhiều mục tiêu ở Syria tuần qua, trong đó có căn cứ lực lượng Mỹ sử dụng, làm tăng lo ngại về nguy cơ xung đột trực diện.', 'Giới chức quân đội Mỹ cho biết không quân Nga thời gian qua tiến hành hàng loạt vụ không kích nhắm vào những lực lượng thân Mỹ tại Syria, khiến Lầu Năm Góc tăng lo ngại nguy cơ tính toán sai lầm dẫn đến xung đột ngoài ý muốn giữa hai cường quốc.', 'Giới quan sát cho rằng nỗi lo này là có cơ sở, trong bối cảnh căng thẳng giữa hai nước vốn đã leo thang nghiêm trọng sau khi Nga mở chiến dịch quân sự đặc biệt ở Ukraine, còn Washington liên tục bơm vũ khí cho Kiev, bất chấp mọi cảnh báo từ Moskva.', 'Nỗi quan ngại lên đến đỉnh điểm hôm 15/6, khi không quân Nga tấn công căn cứ quân sự al-Tanf, gần biên giới Syria - Jordan. Đây là nơi cố vấn Mỹ huấn luyện nhóm dân quân Maghawir al-Thawra được Washington hậu thuẫn, với cái cớ ngăn phiến quân Nhà nước Hồi giáo (IS) tự sưng trỗi dậy.', 'Phía Nga đã báo trước cho Mỹ về cuộc không kích thông qua đường dây nóng, được quân đội hai nước sử dụng trong nhiều năm qua để giảm rủi ro va chạm. Moskva nói chiến dịch nhằm đáp trả một vụ tấn công của phiến quân Maghawir al-Thawra, khiến lực lượng quân đội chính phủ Syria chịu thương vong và mất một phương tiện cơ giới.']\n"
     ]
    }
   ],
   "source": [
    "# đọc file\n",
    "filename='NLP.txt'\n",
    "lines=[]\n",
    "count=0\n",
    "#Max=-1\n",
    "f = open(\"NLP.txt\",\"r\",encoding=\"utf-8\")\n",
    "a = f.readlines()\n",
    "for i in a:\n",
    "    lines.append(i.strip())\n",
    "print(len(lines))\n",
    "print(lines[:5])          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thực hiện tokenize tập input\n",
    "Thêm '\\<s\\>' vào trước mỗi câu, thêm '\\</s\\>' vào sau mỗi câu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: underthesea in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: unidecode in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (1.3.6)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (0.9.8)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (2.27.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (1.1.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (8.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (1.0.2)\n",
      "Requirement already satisfied: underthesea-core==0.0.4_alpha.10 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (0.0.4a10)\n",
      "Requirement already satisfied: nltk in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (4.64.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Click>=6.0->underthesea) (4.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk->underthesea) (2022.4.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->underthesea) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->underthesea) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->underthesea) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->underthesea) (1.26.9)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->underthesea) (1.21.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->underthesea) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->underthesea) (1.7.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->Click>=6.0->underthesea) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->Click>=6.0->underthesea) (3.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\hieun\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_tokens_count= 747\n",
      "14\n",
      "[['<s>', 'nga', 'không kích', 'nhiều', 'mục tiêu', 'ở', 'syria', 'tuần', 'qua', ',', 'trong', 'đó', 'có', 'căn cứ', 'lực lượng', 'mỹ', 'sử dụng', ',', 'làm', 'tăng', 'lo ngại', 'về', 'nguy cơ', 'xung đột', 'trực diện', '.', '</s>'], ['<s>', 'giới chức', 'quân đội', 'mỹ', 'cho', 'biết', 'không quân', 'nga', 'thời gian', 'qua', 'tiến hành', 'hàng loạt', 'vụ', 'không kích', 'nhắm', 'vào', 'những', 'lực lượng', 'thân', 'mỹ', 'tại', 'syria', ',', 'khiến', 'lầu', 'năm', 'góc', 'tăng', 'lo ngại', 'nguy cơ', 'tính toán', 'sai lầm', 'dẫn', 'đến', 'xung đột', 'ngoài', 'ý muốn', 'giữa', 'hai', 'cường quốc', '.', '</s>'], ['<s>', 'giới', 'quan sát', 'cho', 'rằng', 'nỗi', 'lo', 'này', 'là', 'có', 'cơ sở', ',', 'trong', 'bối cảnh', 'căng thẳng', 'giữa', 'hai', 'nước', 'vốn', 'đã', 'leo thang', 'nghiêm trọng', 'sau', 'khi', 'nga', 'mở', 'chiến dịch', 'quân sự', 'đặc biệt', 'ở', 'ukraine', ',', 'còn', 'washington', 'liên tục', 'bơm', 'vũ khí', 'cho', 'kiev', ',', 'bất chấp', 'mọi', 'cảnh báo', 'từ', 'moskva', '.', '</s>'], ['<s>', 'nỗi', 'quan ngại', 'lên', 'đến', 'đỉnh điểm', 'hôm', '15/6', ',', 'khi', 'không', 'quân', 'nga', 'tấn công', 'căn cứ', 'quân sự', 'al-tanf', ',', 'gần', 'biên giới', 'syria', '-', 'jordan', '.', 'đây', 'là', 'nơi', 'cố vấn', 'mỹ', 'huấn luyện', 'nhóm', 'dân quân', 'maghawir', 'al-thawra', 'được', 'washington', 'hậu thuẫn', ',', 'với', 'cái', 'cớ', 'ngăn', 'phiến quân', 'nhà nước', 'hồi giáo', '(', 'is', ')', 'tự', 'sưng', 'trỗi', 'dậy', '.', '</s>'], ['<s>', 'phía', 'nga', 'đã', 'báo', 'trước', 'cho', 'mỹ', 'về', 'cuộc', 'không kích', 'thông qua', 'đường', 'dây nóng', ',', 'được', 'quân đội', 'hai', 'nước', 'sử dụng', 'trong', 'nhiều', 'năm', 'qua', 'để', 'giảm', 'rủi ro', 'va chạm', '. moskva', 'nói', 'chiến dịch', 'nhằm', 'đáp', 'trả', 'một', 'vụ', 'tấn công', 'của', 'phiến quân', 'maghawir', 'al-thawra', ',', 'khiến', 'lực lượng', 'quân đội', 'chính phủ', 'syria', 'chịu', 'thương vong', 'và', 'mất', 'một', 'phương tiện', 'cơ giới', '.', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences \n",
    "import underthesea\n",
    "sentences=[]\n",
    "all_tokens_count=0\n",
    "for line in lines:\n",
    "    tokens = underthesea.word_tokenize(line.lower())\n",
    "    all_tokens_count+=len(tokens)\n",
    "    #sentences.append(tokens)\n",
    "    sentences.append(['<s>']+tokens+['</s>'])\n",
    "print('all_tokens_count=',all_tokens_count)\n",
    "print(len(sentences))\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V= 334\n",
      "n= 747\n",
      "8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# counting 1-gram \n",
    "from collections import Counter\n",
    "counter_unigram=Counter()\n",
    "for sent in sentences:\n",
    "    counter_unigram.update(sent)\n",
    "V=len(counter_unigram)\n",
    "print('V=',V)\n",
    "n=0\n",
    "for gram in counter_unigram:\n",
    "    n+=counter_unigram[gram]\n",
    "n=n-counter_unigram['<s>']-counter_unigram['</s>']\n",
    "print('n=',n)\n",
    "print(counter_unigram['hai'])\n",
    "print(counter_unigram['nước'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761\n",
      "('<s>', 'nga')\n",
      "('nga', 'không kích')\n",
      "('không kích', 'nhiều')\n",
      "V= 667\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "bi_grams=[]\n",
    "for sent in sentences:\n",
    "    gram2=ngrams(sent,2)\n",
    "    bi_grams.extend(gram2)\n",
    "print(len(bi_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(bi_grams[i])\n",
    "\n",
    "counter_bigram = Counter(bi_grams)\n",
    "print('V=',len(counter_bigram))\n",
    "print(counter_bigram[('trỗi','dậy')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747\n",
      "('<s>', 'nga', 'không kích')\n",
      "('nga', 'không kích', 'nhiều')\n",
      "('không kích', 'nhiều', 'mục tiêu')\n",
      "V= 733\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tri_grams=[]\n",
    "for sent in sentences:\n",
    "    gram3=ngrams(sent,3)\n",
    "    tri_grams.extend(gram3)\n",
    "print(len(tri_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(tri_grams[i])\n",
    "\n",
    "counter_trigram = Counter(tri_grams)\n",
    "print('V=',len(counter_trigram))\n",
    "print(counter_trigram[('bơm','vũ khí','cho')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xây dựng dict từ 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nhiệm vụ', 'cái', 'đoàn']\n"
     ]
    }
   ],
   "source": [
    "bi_dict={}\n",
    "set_bi_grams = set(bi_grams)\n",
    "# print(set_bi_grams)\n",
    "for gram in set_bi_grams:\n",
    "    key=(gram[0]) #từ gần nhất \n",
    "    if key in bi_dict.keys():\n",
    "        bi_dict[key].append(gram[1])\n",
    "    else:\n",
    "        bi_dict[key]=[gram[1]]\n",
    "print(bi_dict['với'])\n",
    "#tạo ra quy tắc để chọn 2 từ gần nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n",
      "['f-16', 'với', 'quân đội', 'đang', 'cường kích', 'nga', ',', 'khi', 'trong', 'đơn vị', 'đây', 'iran', '.', 'al-thawra', 'đánh giá', 'cho', 'rằng', 'điều', 'chiến lược', 'đã', 'xung đột', 'đi', 'còn', 'va chạm', 'sử dụng', 'bom', 'qua', 'súng', 'cảnh báo', 'đông', 'quan chức', 'an toàn', '200', 'tập kích', 'ukraine', 'phiên', 'tự', 'is', 'không kích', 'sát', 'đồng minh', 'các', 'chiếc', 'nước', 'gần']\n",
      "hai: ?\n",
      "['cường quốc', 'máy bay', 'nước', 'cường kích', 'tiêm kích', 'bên']\n"
     ]
    }
   ],
   "source": [
    "print(len(bi_dict))\n",
    "print(list(bi_dict.keys())[:45])\n",
    "print('hai: ?')\n",
    "print(bi_dict[('hai')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dùng mô hình vừa xây dựng để sinh các từ tiếp theo với một chuỗi từ cho trước"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'lầu', 'năm', 'góc', 'tăng', 'lo ngại', 'với']\n",
      "0\n",
      "0\n",
      "0\n",
      "nhiệm vụ\n"
     ]
    }
   ],
   "source": [
    "# dự đoán từ tiếp theo\n",
    "seq='lầu năm góc tăng lo ngại'\n",
    "tokens=underthesea.word_tokenize(seq.lower())\n",
    "tokens=['<s>']+tokens\n",
    "print(tokens)\n",
    "i=len(tokens)-1\n",
    "# print(i)\n",
    "key=(tokens[i]) #chuyển về dạng bi-grams \n",
    "#print(key)\n",
    "#print(tri_dict[key])\n",
    "dict_nextword={}\n",
    "\n",
    "#dự đoán từ tiếp theo\n",
    "for next_word in bi_dict[key]:\n",
    "    #print(counter_trigram[(key[0],key[1],next_word)])\n",
    "    #counter_bigram : đếm số lần xuất hiện của các cặp từ, chọn cặp từ có số lần xuất hiện nhiều nhất\n",
    "    dict_nextword[next_word]=counter_bigram[(key[0],next_word)] \n",
    "sorted_dict=sorted(dict_nextword,key=dict_nextword.__getitem__,reverse=True)\n",
    "#print(dict_nextword)\n",
    "print(sorted_dict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dự đoán chuỗi K từ tiếp theo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'nga', 'không kích', 'nhiều']\n",
      "nga không kích nhiều mục tiêu ở syria đã triển khai hai bên khiến lầu năm\n"
     ]
    }
   ],
   "source": [
    "# dự đoán chuỗi K từ tiếp theo\n",
    "seq='nga không kích nhiều'\n",
    "tokens=underthesea.word_tokenize(seq.lower())\n",
    "tokens=['<s>']+tokens\n",
    "print(tokens)\n",
    "N=10\n",
    "count=0\n",
    "while count<N:\n",
    "    count+=1\n",
    "    i=len(tokens)-1\n",
    "    key=(tokens[i])\n",
    "    #print(tri_dict[key])\n",
    "    dict_nextword={}\n",
    "    if not (key in bi_dict.keys()):\n",
    "        break\n",
    "    for next_word in bi_dict[key]:\n",
    "        dict_nextword[next_word]=counter_bigram[(key[0],next_word)] \n",
    "    sorted_dict=sorted(dict_nextword,key=dict_nextword.__getitem__,reverse=True)\n",
    "    #print(dict_nextword)\n",
    "    #print(sorted_dict[0])\n",
    "    tokens.append(sorted_dict[0])\n",
    "    seq+= ' '+sorted_dict[0]\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d65b2b009303c0af65e9c9d4be8f26c2c45182fd085ae18c2ed3b904a6fa84e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
