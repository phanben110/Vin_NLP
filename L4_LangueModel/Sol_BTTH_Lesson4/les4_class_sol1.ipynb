{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Mô hình ngôn ngữ và ứng dụng trong việc sinh văn bản\n",
    "\n",
    "#### Mục tiêu: xây dựng chương trình sinh văn bản tiếng Việt đơn giản \n",
    "\n",
    "Bài 1:  \n",
    "\n",
    "a)\tXây dựng mô hình ngôn ngữ dựa trên n-gram sử dụng phương pháp smoothing là Laplace, cho các mô hình:\n",
    "-\t1-gram\n",
    "-\t2-gram\n",
    "-\t3-gram\n",
    "\n",
    "b)\tTính xác suất của một câu và tính Perplexity của một câu dựa theo 1-gram, 2-gram, 3-gram\n",
    "\n",
    "c)\tPhân tích kết quả\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đọc file input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['Nga không kích nhiều mục tiêu ở Syria tuần qua, trong đó có căn cứ lực lượng Mỹ sử dụng, làm tăng lo ngại về nguy cơ xung đột trực diện.', 'Giới chức quân đội Mỹ cho biết không quân Nga thời gian qua tiến hành hàng loạt vụ không kích nhắm vào những lực lượng thân Mỹ tại Syria, khiến Lầu Năm Góc tăng lo ngại nguy cơ tính toán sai lầm dẫn đến xung đột ngoài ý muốn giữa hai cường quốc.', 'Giới quan sát cho rằng nỗi lo này là có cơ sở, trong bối cảnh căng thẳng giữa hai nước vốn đã leo thang nghiêm trọng sau khi Nga mở chiến dịch quân sự đặc biệt ở Ukraine, còn Washington liên tục bơm vũ khí cho Kiev, bất chấp mọi cảnh báo từ Moskva.', 'Nỗi quan ngại lên đến đỉnh điểm hôm 15/6, khi không quân Nga tấn công căn cứ quân sự al-Tanf, gần biên giới Syria - Jordan. Đây là nơi cố vấn Mỹ huấn luyện nhóm dân quân Maghawir al-Thawra được Washington hậu thuẫn, với cái cớ ngăn phiến quân Nhà nước Hồi giáo (IS) tự sưng trỗi dậy.', 'Phía Nga đã báo trước cho Mỹ về cuộc không kích thông qua đường dây nóng, được quân đội hai nước sử dụng trong nhiều năm qua để giảm rủi ro va chạm. Moskva nói chiến dịch nhằm đáp trả một vụ tấn công của phiến quân Maghawir al-Thawra, khiến lực lượng quân đội chính phủ Syria chịu thương vong và mất một phương tiện cơ giới.']\n"
     ]
    }
   ],
   "source": [
    "# đọc file\n",
    "filename='NLP.txt'\n",
    "lines=[]\n",
    "#Max=-1\n",
    "f = open(\"NLP.txt\",\"r\",encoding=\"utf-8\")\n",
    "a = f.readlines()\n",
    "for i in a:\n",
    "    lines.append(i.strip())\n",
    "print(len(lines))\n",
    "print(lines[:5])          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cài đặt thư viện xử lý ngôn ngữ underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: underthesea in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (3.7)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (0.9.8)\n",
      "Requirement already satisfied: requests in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (2.27.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (1.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (4.64.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (6.0)\n",
      "Requirement already satisfied: underthesea-core==0.0.4_alpha.10 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (0.0.4a10)\n",
      "Requirement already satisfied: unidecode in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (1.3.6)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from underthesea) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Click>=6.0->underthesea) (4.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk->underthesea) (2022.4.24)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->underthesea) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->underthesea) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->underthesea) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->underthesea) (3.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->underthesea) (1.21.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->underthesea) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->underthesea) (1.7.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->Click>=6.0->underthesea) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->Click>=6.0->underthesea) (3.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hieun\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thực hiện tokenize tập input\n",
    "Thêm '\\<s\\>' vào trước mỗi câu, thêm '\\</s\\>' vào sau mỗi câu và lower text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_tokens_count= 747\n",
      "14\n",
      "[['<s>', 'nga', 'không kích', 'nhiều', 'mục tiêu', 'ở', 'syria', 'tuần', 'qua', ',', 'trong', 'đó', 'có', 'căn cứ', 'lực lượng', 'mỹ', 'sử dụng', ',', 'làm', 'tăng', 'lo ngại', 'về', 'nguy cơ', 'xung đột', 'trực diện', '.', '</s>'], ['<s>', 'giới chức', 'quân đội', 'mỹ', 'cho', 'biết', 'không quân', 'nga', 'thời gian', 'qua', 'tiến hành', 'hàng loạt', 'vụ', 'không kích', 'nhắm', 'vào', 'những', 'lực lượng', 'thân', 'mỹ', 'tại', 'syria', ',', 'khiến', 'lầu', 'năm', 'góc', 'tăng', 'lo ngại', 'nguy cơ', 'tính toán', 'sai lầm', 'dẫn', 'đến', 'xung đột', 'ngoài', 'ý muốn', 'giữa', 'hai', 'cường quốc', '.', '</s>'], ['<s>', 'giới', 'quan sát', 'cho', 'rằng', 'nỗi', 'lo', 'này', 'là', 'có', 'cơ sở', ',', 'trong', 'bối cảnh', 'căng thẳng', 'giữa', 'hai', 'nước', 'vốn', 'đã', 'leo thang', 'nghiêm trọng', 'sau', 'khi', 'nga', 'mở', 'chiến dịch', 'quân sự', 'đặc biệt', 'ở', 'ukraine', ',', 'còn', 'washington', 'liên tục', 'bơm', 'vũ khí', 'cho', 'kiev', ',', 'bất chấp', 'mọi', 'cảnh báo', 'từ', 'moskva', '.', '</s>'], ['<s>', 'nỗi', 'quan ngại', 'lên', 'đến', 'đỉnh điểm', 'hôm', '15/6', ',', 'khi', 'không', 'quân', 'nga', 'tấn công', 'căn cứ', 'quân sự', 'al-tanf', ',', 'gần', 'biên giới', 'syria', '-', 'jordan', '.', 'đây', 'là', 'nơi', 'cố vấn', 'mỹ', 'huấn luyện', 'nhóm', 'dân quân', 'maghawir', 'al-thawra', 'được', 'washington', 'hậu thuẫn', ',', 'với', 'cái', 'cớ', 'ngăn', 'phiến quân', 'nhà nước', 'hồi giáo', '(', 'is', ')', 'tự', 'sưng', 'trỗi', 'dậy', '.', '</s>'], ['<s>', 'phía', 'nga', 'đã', 'báo', 'trước', 'cho', 'mỹ', 'về', 'cuộc', 'không kích', 'thông qua', 'đường', 'dây nóng', ',', 'được', 'quân đội', 'hai', 'nước', 'sử dụng', 'trong', 'nhiều', 'năm', 'qua', 'để', 'giảm', 'rủi ro', 'va chạm', '. moskva', 'nói', 'chiến dịch', 'nhằm', 'đáp', 'trả', 'một', 'vụ', 'tấn công', 'của', 'phiến quân', 'maghawir', 'al-thawra', ',', 'khiến', 'lực lượng', 'quân đội', 'chính phủ', 'syria', 'chịu', 'thương vong', 'và', 'mất', 'một', 'phương tiện', 'cơ giới', '.', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences \n",
    "import underthesea\n",
    "sentences=[]\n",
    "all_tokens_count=0\n",
    "for line in lines:\n",
    "    tokens = underthesea.word_tokenize(line.lower())\n",
    "    all_tokens_count+=len(tokens)\n",
    "    #sentences.append(tokens)\n",
    "    sentences.append(['<s>']+tokens+['</s>'])\n",
    "print('all_tokens_count=',all_tokens_count)\n",
    "print(len(sentences))\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V= 334\n",
      "n= 747\n",
      "9\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# counting 1-gram \n",
    "from collections import Counter\n",
    "counter_unigram=Counter()\n",
    "for sent in sentences:\n",
    "    counter_unigram.update(sent)\n",
    "V=len(counter_unigram)\n",
    "print('V=',V)\n",
    "n=0\n",
    "for gram in counter_unigram:\n",
    "    n+=counter_unigram[gram]\n",
    "n=n-counter_unigram['<s>']-counter_unigram['</s>']\n",
    "print('n=',n)\n",
    "print(counter_unigram['của'])\n",
    "print(counter_unigram['dậy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761\n",
      "('<s>', 'nga')\n",
      "('nga', 'không kích')\n",
      "('không kích', 'nhiều')\n",
      "V= 667\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "bi_grams=[]\n",
    "for sent in sentences:\n",
    "    gram2=ngrams(sent,2)\n",
    "    bi_grams.extend(gram2)\n",
    "print(len(bi_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(bi_grams[i])\n",
    "\n",
    "counter_bigram = Counter(bi_grams)\n",
    "print('V=',len(counter_bigram))\n",
    "print(counter_bigram[('chiến dịch','quân sự')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747\n",
      "('<s>', 'nga', 'không kích')\n",
      "('nga', 'không kích', 'nhiều')\n",
      "('không kích', 'nhiều', 'mục tiêu')\n",
      "V= 733\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tri_grams=[]\n",
    "for sent in sentences:\n",
    "    gram3=ngrams(sent,3)\n",
    "    tri_grams.extend(gram3)\n",
    "print(len(tri_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(tri_grams[i])\n",
    "\n",
    "counter_trigram = Counter(tri_grams)\n",
    "print('V=',len(counter_trigram))\n",
    "print(counter_trigram[('để','giảm','rủi ro')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viết hàm tính xác suất cho từng loại: 1-gram, 2-gram, 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính prob theo từng loại: 1-gram, 2-gram, 3-gram\n",
    "def uni_prob(word):\n",
    "    return max(1,counter_unigram[word])/all_tokens_count\n",
    "\n",
    "def bi_prob(word1,word2):\n",
    "    if counter_bigram[(word1,word2)]>0:\n",
    "        return counter_bigram[(word1,word2)]/counter_unigram[word1]\n",
    "    else:\n",
    "        return 0.4*uni_prob(word2)\n",
    "    \n",
    "def tri_prob(word1,word2,word3):\n",
    "    if counter_trigram[(word1,word2,word3)]>0:\n",
    "        return counter_trigram[(word1,word2,word3)]/counter_bigram[(word1,word2)]\n",
    "    else:\n",
    "        return 0.4*bi_prob(word1,word2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viết hàm tính xác xuất cho một câu, normalize theo 1 từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính xác suất của một câu, normalize theo 1 từ \n",
    "def probLM(sent,n):\n",
    "    if n>3 or n<1: # không xét trường hợp này \n",
    "        return 0\n",
    "    tokens=underthesea.word_tokenize(sent.lower())\n",
    "    tokens += ['<s>']+tokens\n",
    "    \n",
    "    prob=1\n",
    "    for i in range(1,len(tokens)):\n",
    "        if n==1:\n",
    "            prob*=uni_prob(tokens[i])\n",
    "        elif n==2:\n",
    "            prob*=bi_prob(tokens[i-1],tokens[i])\n",
    "        elif n==3:\n",
    "            if i>=2:\n",
    "                prob*=tri_prob(tokens[i-2],tokens[i-1],tokens[i])\n",
    "            else:\n",
    "                prob*=bi_prob(tokens[i-1],tokens[i])\n",
    "    l=len(tokens)-1\n",
    "    return prob**(1/l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kiểm tra xác xuất của 1 câu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1\n",
      "prob= 0.002900922772845714\n",
      "perplexity= 344.7178978222269\n",
      "n=2\n",
      "prob= 0.0011603691091382857\n",
      "perplexity= 861.7947445555671\n",
      "n=3\n",
      "prob= 0.00044474669896677735\n",
      "perplexity= 2248.4708763958697\n"
     ]
    }
   ],
   "source": [
    "sent='Mai là 1 ngày đẹp trời để đi đâu đó, có thể là đón em.'\n",
    "print('n=1')\n",
    "pr=probLM(sent,1)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "print('n=2')\n",
    "pr=probLM(sent,2)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "print('n=3')\n",
    "pr=probLM(sent,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So sánh xác suất của 2 câu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob= 0.0007151697849874138\n",
      "perplexity= 1398.2693634317882\n",
      "prob= 0.00035710472804806673\n",
      "perplexity= 2800.298964020994\n"
     ]
    }
   ],
   "source": [
    "# kiểm tra xem 2 câu có xác suất hơn nhau thế nào, ví dụ cho bài toán speech to text\n",
    "sent1='Cuộc sống mà không có âm nhạc thì thật là chán.'\n",
    "sent2='Cuộc sống mà ko có am nhạc thi thật là trán.'\n",
    "pr=probLM(sent1,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "pr=probLM(sent2,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1351fcf4d9a71a0a7642ff753eb3792ce6ab1ef3fbcd1886aadc4d216688484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
