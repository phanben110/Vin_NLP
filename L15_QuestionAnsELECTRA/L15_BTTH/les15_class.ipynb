{"cells":[{"cell_type":"markdown","metadata":{"id":"Sf6G6lYWjDEv"},"source":["# ELECTRA for Question Answering on SQUAD\n","Trong notebook này ta sẽ làm quen với mô hình Electra ứng dụng cho bài toán Question Answering. Electra là một phương pháp học biểu diễn ngôn ngữ (language  representation learning) được ứng dụng cho nhiều bài toán khác nhau, ví dụ như Classification, QA, Text chunking. Đây là một phương pháp học biểu diễn mới, cho phép chúng ta đạt được hiệu năng cao với các Benchmark task trong NLP như SQUAD và GLUE (chi tiết xem tại paper [ ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://openreview.net/pdf?id=r1xMH1BtvB)).\n","\n","Stanford Question Answering Dataset (SQuAD) là một dataset cho bài toán đọc hiểu và trả lời câu hỏi được phát triển bởi đại học Stanford. Trong đó, với mỗi bản ghi, một hệ thống AI sẽ được cung cấp một đoạn văn bản để đọc hiểu và một câu hỏi, nhiệm vụ của hệ thống AI đó là trả lời câu hỏi đó bằng một đoạn trích từ đoạn văn bản được cung cấp nếu có thể, hoặc báo lại là không thể trả lời nếu đoạn văn cung cấp không thể dùng để trả lời câu hỏi.\n","\n","ELECTRA được công bố với ba phiên bản theo kích thước tăng dần như sau: Small, Base, Large. Vì giới hạn về thời gian cũng như khả năng tính toán, trong notebook này ta sẽ tiến hành thử nghiệm với mô hình ELECTRA Small. Học viên nên chạy bài thực hành này trên notebook nếu không có server để hỗ trợ\n"]},{"cell_type":"markdown","metadata":{"id":"2ZgQnS6Sf3_A"},"source":["## Bước 1: Setup môi trường trên Google Colab\n","Học viên sử dụng nền tảng tính toán khác ngoài Google Colan có thể bỏ qua bước này. Trước khi chạy những câu lệnh dưới, ta chọn cấu hình GPU bằng cách ấn: **Runtime** -> **Change runtime type** -> **GPU**"]},{"cell_type":"markdown","metadata":{"id":"EO81tsFU9qUb"},"source":["### 1.1. Mount máy ảo vào drive của chúng ta"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LzljnbuCakZL","vscode":{"languageId":"python"}},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"tF8GPVzd-wo-"},"source":["### 1.2. Cài đặt thư viện và tải mã nguồn ELECTRA\n","\n","Trong bài thực hành này, ta sẽ sử dụng mã nguồn ELECTRA do bên Google Research phát triển. Để sử dụng mã nguồn này ta sẽ phải cài thư viện tensorflow==1.15 và"]},{"cell_type":"markdown","metadata":{"id":"Q6UuMLAZfm1Y"},"source":["***Đầu tiên ta cài đặt tensorflow phiên bản 1.15***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QF6pVDYcdv_A","vscode":{"languageId":"python"}},"outputs":[],"source":["!pip install tensorflow==1.15"]},{"cell_type":"markdown","metadata":{"id":"FTpZ4wfTf-zt"},"source":["***Sau đó, ta clone git repo của ELECTRA về không gian làm việc và cd và thư mục `electra`***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mk_fE4x5aq98","vscode":{"languageId":"python"}},"outputs":[],"source":["!git clone https://github.com/google-research/electra.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oEoOUhlka2Xn","vscode":{"languageId":"python"}},"outputs":[],"source":["cd electra/"]},{"cell_type":"markdown","metadata":{"id":"bA6IZdoNgJlV"},"source":["***Tiếp theo, ta download và unzip file mô hình của phiên bản ELECTRA Small***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITYpDtIqa8o6","vscode":{"languageId":"python"}},"outputs":[],"source":["!wget https://storage.googleapis.com/electra-data/electra_small.zip\n","!unzip electra_small.zip"]},{"cell_type":"markdown","metadata":{"id":"sVKhT6v1CxpI"},"source":["## Bước 2: Download và quan sát dữ liệu"]},{"cell_type":"markdown","metadata":{"id":"ylmfAql7gQH8"},"source":["### 2.1. Download training và validation data của bộ Squad 2.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T91wCPr4bHtE","vscode":{"languageId":"python"}},"outputs":[],"source":["!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n","!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"]},{"cell_type":"markdown","metadata":{"id":"hH6TF-cShFlS"},"source":["### 2.2. Tạo thư mục để chứa dữ liệu huấn luyện và chuyển data vào thư mục đó\n","***Đầu tiên, ta tạo một thư mục tên là `data` để chứa dữ liệu và file models***\n","\n","*Trong đó, theo quy ước của mã nguồn:*\n"," - `finetuning_data/<tên tác vụ>` là thư mục chứa data cho tác vụ tương ứng, vì chúng ta đang làm bài toán Question Answering, nên tên thư mục con sẽ để là `squad`.\n"," - `models` là thư mục chứa model của electra mà ta muốn sử dụng\n","\n","Sau khi tạo hai thư mục này rồi, ta chuyển hai file json chứa dữ liệu của SQuAD 2.0 vào thư mục `squad`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_1cxdrIcUfe","vscode":{"languageId":"python"}},"outputs":[],"source":["!mkdir -p data/finetuning_data/squad\n","!mkdir -p data/models/\n","!mv dev-v2.0.json data/finetuning_data/squad/dev.json\n","!mv train-v2.0.json data/finetuning_data/squad/train.json"]},{"cell_type":"markdown","metadata":{"id":"mVJcu919Hj55"},"source":["Tiếp theo, ta copy file vocab.txt từ thư mục `electra_small` sang thư mục `data`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ql5ZxQkmonHf","vscode":{"languageId":"python"}},"outputs":[],"source":["!cp electra_small/vocab.txt data/vocab.txt"]},{"cell_type":"markdown","metadata":{"id":"neVPsrSTJdGj"},"source":["Cuối cùng, ta copy thư mục `electra_small` vào trong thư mục `data/models`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPHi8bSSo1qN","vscode":{"languageId":"python"}},"outputs":[],"source":["import shutil\n","shutil.copytree('electra_small', 'data/models/electra_small', copy_function = shutil.copy) "]},{"cell_type":"markdown","metadata":{"id":"YOH3wIQEJzuo"},"source":["### 2.3. Quan sát dữ liệu\n","\n","Bây giờ, ta sẽ thực hiện một vài thao tác thống kê để hiểu thêm về dữ liệu của Squad"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7rev4UrMeFa","vscode":{"languageId":"python"}},"outputs":[],"source":["import os\n","os.listdir(\"data/finetuning_data/squad\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oh8EJSfJMhlo","vscode":{"languageId":"python"}},"outputs":[],"source":["import json\n","from pprint import pprint\n","import numpy as np\n","\n","\n","def view_squad_info(subset = 'train', get_impossible_exp = False):\n","    with open(\"data/finetuning_data/squad/{}.json\".format(subset), \"r\") as f:\n","      data = json.load(f)\n","    \n","    # Thống kê số văn bản\n","    numOfParagraph = 0\n","    # YOUR CODE HERE\n","\n","\n","    # YOUR CODE HERE\n","    \n","    \n","    # Thống kê số cặp câu hỏi câu trả lời\n","    numOfQaPair = 0\n","     # YOUR CODE HERE\n","\n","\n","\n","    # YOUR CODE HERE      \n","\n","    \n","    # Thống kê độ dài của context\n","    ContextLen = []\n","    # YOUR CODE HERE\n","\n","\n","\n","    maxContextLen = None\n","    # YOUR CODE HERE\n","    \n","\n","    # Thống kê độ dài của query và answer\n","    queryLen = [] # Độ dài của các query\n","    ansLen = [] # Độ dài của các câu trả lời\n","\n","    # YOUR CODE HERE\n","    \n","\n","\n","    \n","    # YOUR CODE HERE\n","\n","\n","    avgQueLen = np.mean(queryLen)\n","    avgAnsLen = np.mean(ansLen)\n","\n","\n","    print(\"Phiên bản SQuAd là {}\".format(data[\"version\"]))\n","    print(\"Số văn bản trong dataset là {}\".format(len(data[\"data\"])))\n","    print(\"Mỗi văn bản có những key sau: {}\".format(data[\"data\"][0].keys()))\n","    print(\"Số đoạn văn trong dataset là: {}\".format(numOfParagraph))\n","    print(\"Số cặp câu hỏi và trả lời trong dataset là: {}\".format(numOfQaPair))\n","    print(\"Độ dài tối đa của một đoạn văn là: {}\".format(maxContextLen))\n","    print(\"Độ dài trung bình của một câu hỏi là: {}\".format(avgQueLen))\n","    print(\"Độ dài trung bình của một trả lời là: {}\".format(avgAnsLen))\n","    \n","    print(\"------MỘT SỐ CẶP CÂU VÍ DỤ-----\")\n","    pprint(data[\"data\"][0]['paragraphs'][0][\"qas\"][0:2])\n","    print(\"-------------------------------\")\n","    pprint(data[\"data\"][-1]['paragraphs'][0][\"qas\"][0:2])\n","\n","    if get_impossible_exp:\n","      for i in range(len(data[\"data\"])):\n","        for j in range(len(data[\"data\"][i]['paragraphs'])):\n","          for k in range(len(data[\"data\"][i]['paragraphs'][j][\"qas\"])):\n","            if data[\"data\"][i]['paragraphs'][j][\"qas\"][k]['is_impossible']:\n","              pprint(data[\"data\"][i]['paragraphs'][j][\"qas\"][k])"]},{"cell_type":"markdown","metadata":{"id":"pOMUw_A33upK"},"source":["Ta sử dụng hàm `view_squad_info` để xem thông tin của dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3AkYbf2i18-1","vscode":{"languageId":"python"}},"outputs":[],"source":["view_squad_info(subset = 'train')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhhXyHDoNIr4","vscode":{"languageId":"python"}},"outputs":[],"source":["view_squad_info(subset = 'dev', get_impossible_exp= False)"]},{"cell_type":"markdown","metadata":{"id":"CKOvdlks6Ubq"},"source":["Bên trên là một vài thông số cơ bản của SQuAD dataset. Nếu như ta muốn sử dụng lại mô hình ELECTRA cho bài toán Question-Answering, ta có thể làm hai việc sau:\n","- Xây dựng ngữ liệu cho ngôn ngữ mà bạn muốn xây dựng mô hình từ đó và tạo file vocab.txt tương ứng, sau đó chạy file run_finetuning.py trong mã nguồn để có được mô hình electra custom của bạn\n","- Thiết kế một dataset có cấu trúc giống như trên và lắp ghép với mã nguồn trong bài thực hành này.\n","\n","Và đương nhiên, là phải có một server thật khỏe để chạy!"]},{"cell_type":"markdown","metadata":{"id":"lLANtEQjKedl"},"source":["## Bước 3: Training\n","\n","Ta chạy dòng lệnh dưới đây để thực hiện training, chúng ta có thể thay đổi các tham số trong hparams và theo dõi sự khác biệt trong quá trình huấn luyện"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kQuTT83do2Z","vscode":{"languageId":"python"}},"outputs":[],"source":["# YOUR CODE HERE\n","# gọi thông qua !python3 run_finetuning.py\n","# Tham số: model_size=\"small\", task_names=[\"squad\"], eval_batch_size=16, beam_size=20, train_batch_size=32\n","\n","# YOUR CODE HERE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7pndpkd4K1fI","vscode":{"languageId":"python"}},"outputs":[],"source":["# YOUR CODE HERE\n","#đọc và in kết quả prediction\n","\n","\n","\n","# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"6VCFVQAWLXuM"},"source":["Mô hình đang đạt được độ chính xác tầm 65% và f1 là 67% trên tập test của Squad, ta có thể cải thiện mô hình bằng cách chỉnh các tham số cho phù hợp và chạy mô hình với số epoch lớn hơn. Nếu như bạn có hệ thống máy mạnh hơn, bạn có thể thử nghiệm với các phiên bản lớn hơn của electra"]},{"cell_type":"markdown","metadata":{},"source":["Sau khi chạy xong mô hình chúng ta có thể test bài toán bằng 1 pretrain model của transformer để hiểu rõ cũng như tối giản việc code. \n","\n","Tham khảo tài liệu ở [đây](https://huggingface.co/deepset/electra-base-squad2)\n","\n","Dữ liệu test sẽ là:\n","\n","\n","\n","```\n","'question': 'How does this work?',\n","'context' : 'This works fine.',\n","'context': 'This works perfectly.',\n","'context': 'Its not working at all.'\n","```\n","Hoặc bạn có thẻ thay đổi bất lỳ câu hỏi và trả lời bằng tiếng anh nào nếu muốn."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["!pip install transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n","\n","model_name = \"deepset/electra-base-squad2\"\n","### YOUR CODE HERE ###\n","\n","\n","### END YOUR CODE ###\n","\n","# b) Load model & tokenizer\n","model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Training_ELECTRA_Squad_Colab.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
